# Checkpoint 2 - Treinamento de Redes Neurais com Keras

Este reposit√≥rio cont√©m a resolu√ß√£o da atividade de Treinamento de Redes Neurais com Keras para dados tabulares, da disciplina de Arquiteturas Disruptivas.

O c√≥digo completo dos experimentos est√° no arquivo `exercicios_keras.ipynb.ipynb`.

## üë®‚Äçüíª Integrantes

- Arthur Bispo de Lima - RM:557568
- Jo√£o Paulo Moreira dos Santos RM:557808

### Como Rodar os Experimentos

O projeto foi desenvolvido utilizando o Google Colab e os dados foram carregados diretamente na sess√£o. Para replicar os resultados, siga os passos abaixo:

**1. Pr√©-requisitos:**
* Uma conta Google para acessar o [Google Colab](https://colab.research.google.com/). Nenhuma instala√ß√£o local √© necess√°ria.

**2. Obten√ß√£o dos Dados:**
* Os arquivos de dados necess√°rios, `wine.data` e `cal_housing.data`, est√£o dispon√≠veis neste pr√≥prio reposit√≥rio.
* Fa√ßa o download dos dois arquivos para a sua m√°quina local.

**3. Execu√ß√£o:**
1.  Abra o arquivo `.ipynb` deste reposit√≥rio no Google Colab.
2.  No menu √† esquerda do Colab, clique no √≠cone de **Pasta** para abrir o painel de arquivos.
3.  Clique no √≠cone de **Upload** (uma p√°gina com uma seta para cima) e suba os dois arquivos de dados (`wine.data` e `cal_housing.data`) que voc√™ baixou deste reposit√≥rio.
4.  Com os arquivos na sess√£o, execute todas as c√©lulas do noteb
---

### Exerc√≠cio 1 ‚Äì Classifica√ß√£o Multiclasse (Wine Dataset)

**Objetivo:** Treinar uma rede neural para classificar vinhos em 3 classes e comparar seu desempenho com um modelo do Scikit-learn.

**Modelos Utilizados:**
1.  Rede Neural (Keras) com 2 camadas ocultas de 32 neur√¥nios.
2.  RandomForestClassifier (Scikit-learn) com 100 estimadores.

**Resultados:**
* **Acur√°cia da Rede Neural:** 100.00%
* **Acur√°cia do RandomForestClassifier:** 100.00%

**Discuss√£o:**

Para a tarefa de classifica√ß√£o do Wine Dataset, tanto a Rede Neural constru√≠da com Keras quanto o modelo RandomForestClassifier do Scikit-learn alcan√ßaram uma acur√°cia perfeita de 100.00% no conjunto de teste.

Apesar do desempenho id√™ntico na m√©trica final, a an√°lise do processo revela diferen√ßas importantes. O RandomForestClassifier se mostrou uma solu√ß√£o mais simples e direta, exigindo menos pr√©-processamento dos dados e um tempo de treinamento significativamente menor.

Por outro lado, a Rede Neural, embora igualmente eficaz, demandou uma implementa√ß√£o mais complexa, incluindo a padroniza√ß√£o dos dados e a codifica√ß√£o one-hot dos r√≥tulos. A an√°lise do hist√≥rico de treinamento tamb√©m indicou um leve sinal de overfitting, onde o modelo se ajustou perfeitamente aos dados de treino em detrimento da generaliza√ß√£o, um risco que precisa ser monitorado em arquiteturas de deep learning.

Resultado:

Para este dataset tabular espec√≠fico, o `RandomForestClassifier` foi o modelo superior em termos de simplicidade e efici√™ncia, entregando o mesmo resultado de ponta com menos esfor√ßo de implementa√ß√£o.

---

### Exerc√≠cio 2 ‚Äì Regress√£o (California Housing Dataset)

**Objetivo:** Treinar uma rede neural para prever o valor m√©dio das casas e comparar seu desempenho com um modelo do Scikit-learn.

**Modelos Utilizados:**
1.  Rede Neural (Keras) com 3 camadas ocultas (64, 32, 16 neur√¥nios).
2.  RandomForestRegressor (Scikit-learn) com 100 estimadores.

**Resultados (Erro M√©dio Absoluto - MAE):**
* **MAE da Rede Neural:** ~$46,525.62
* **MAE do RandomForestRegressor:** $31,971.65

**Discuss√£o:**
Para a tarefa de regress√£o de previs√£o dos pre√ßos de im√≥veis no dataset da Calif√≥rnia, foram comparados uma Rede Neural (Keras) e um modelo RandomForestRegressor (Scikit-learn).

As m√©tricas de erro mostraram um vencedor claro. O RandomForestRegressor alcan√ßou um Erro M√©dio Absoluto (MAE) de $31,971.65. 

Enquanto a Rede Neural obteve um MAE de aproximadamente $46,525.62. 

Isso indica que o modelo de Random Forest foi significativamente mais preciso, com um erro m√©dio de previs√£o quase $15.000 inferior.

Al√©m da performance superior, o RandomForestRegressor tamb√©m se provou uma solu√ß√£o mais eficiente, com menor complexidade de c√≥digo, sem necessidade de pr√©-processamento de scaling e com tempo de treinamento muito inferior. A Rede Neural, por sua vez, apresentou um bom processo de aprendizado sem sinais de overfitting, mas n√£o foi capaz de atingir o mesmo n√≠vel de precis√£o do modelo cl√°ssico de Machine Learning.

Conclus√£o: Para este dataset tabular de regress√£o, o `RandomForestRegressor` demonstrou ser o modelo superior tanto em performance (menor erro) quanto em efici√™ncia de implementa√ß√£o.
